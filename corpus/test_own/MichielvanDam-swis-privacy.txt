Content-based Privacy Management on the Social Web
Summary
Users post all kind of details about themselves on social websites. Most of the social websites have lots of privacy options, but these either aren't comprehensive or too cumbersome. What is needed is a privacy manager that for every post you make suggests the right audience for that post. Each post can then be shared with the people that you want to read it, without exposing privacy-sensitive information to people whom you rather keep it from. For that purpose the authors developed a system that automatically determines a list of recipients, based on the content of the post.
The authors use Named Entity Recognition to determine the entities in a message, and use that to determine which privacy annotations are used in a message: location, person, time/date, activity and organization. Based on the available privacy annotations, social context and background context, rules are defined to allow or deny specific types of message for specific types of contacts, e.g. for Friends, Work relations, or Family.
A short evaluation of the privacy suggestions was done using a small dataset of simulated facebook posts. Fully automated suggestions were compared to user-corrected suggestions, which seemed to show a good performance for the automated suggestions.
Review
The authors claim to introduce (1) an intelligent privacy manager, (2) a novel privacy policy language, (3) a prototype of the manager on the facebook platform, and (4) an evaluation on a small test scenario. 
The intelligent privacy manager is well-defined in the article, including the considerations that are taken into account when deciding on the audience for a message. However, the novel privacy policy language at the core of this privacy manager is only described on a high level, lacking specifics. This lack of detail is also present at the prototype and the test scenario, where the authors omit how they selected or constructed the messages in the test set. Because both the details of the implementation and the dataset used for the test aren't apparent, the results can not easily be verified by other researchers, making them appear less trustworthy.
The conclusion mentions that "The danger is that the number and complexity of rules required to capture preferences of an average user can be high." which is not supported by or even mentioned in the body of the paper.
The topic is interesting, and the authors make a good case for needing a more automated privacy manager that's also fine-grained to the user. However, more detail is needed in the specification of the language and automated decisions, before this work can be applied independently.
